{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2a4d1d8",
   "metadata": {},
   "source": [
    "# Automotive Equity Research: A Multi-Step Agentic Workflow\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/run-llama/llama_cloud_services-demo/blob/main/examples/extract/automotive_sector_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "This notebook demonstrates an end‑to‑end agentic workflow using LlamaExtract and the LlamaIndex event‑driven workflow framework for automotive sector analysis.\n",
    "\n",
    "In this workflow, we:\n",
    "1. **Extract** key financial metrics from Q2 2024 earnings reports for Tesla and Ford.\n",
    "2. **Generate** a preliminary financial model summary for each company using an LLM.\n",
    "3. **Cross‑reference** Tesla's metrics with Ford's data to produce a final equity research memo.\n",
    "4. **Output** the memo as structured JSON.\n",
    "\n",
    "This workflow is designed for equity research analysts and investment professionals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2aed8c8-c86a-4f1f-911c-bb1fbcfd6b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_api_key = \"\"\n",
    "openai_api_key = \"\"\n",
    "openai_api_url = \"\"\n",
    "project_id=\"\"\n",
    "organization_id=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9993d4d-a1bd-43d7-a150-7e1418070b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('data/automotive_sector_analysis/ford_q2_earnings_press_release.pdf',\n",
       " <http.client.HTTPMessage at 0x1fc80063230>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(\"data/automotive_sector_analysis\", exist_ok=True)\n",
    "\n",
    "# Download the Tesla Q2 earnings PDF\n",
    "tesla_url = \"https://digitalassets.tesla.com/tesla-contents/image/upload/IR/TSLA-Q2-2024-Update.pdf\"\n",
    "tesla_path = \"data/automotive_sector_analysis/tesla_q2_earnings.pdf\"\n",
    "urllib.request.urlretrieve(tesla_url, tesla_path)\n",
    "\n",
    "# Download the Ford Q2 earnings PDF\n",
    "ford_url = \"https://s205.q4cdn.com/882619693/files/doc_financials/2024/q2/Q2-2024-Ford-Earnings-Press-Release.pdf\"\n",
    "ford_path = \"data/automotive_sector_analysis/ford_q2_earnings_press_release.pdf\"\n",
    "urllib.request.urlretrieve(ford_url, ford_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2b2ea4",
   "metadata": {},
   "source": [
    "## Define the Output Schema\n",
    "\n",
    "We define a schema to represent the final equity research memo. This includes the company name, a summary of the financial model, a comparative analysis, and an overall recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "492f8bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field, ConfigDict\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "class RawFinancials(BaseModel):\n",
    "    revenue: Optional[float] = Field(\n",
    "        None, description=\"Extracted revenue (in million USD)\"\n",
    "    )\n",
    "    operating_income: Optional[float] = Field(\n",
    "        None, description=\"Extracted operating income (in million USD)\"\n",
    "    )\n",
    "    eps: Optional[float] = Field(None, description=\"Extracted earnings per share\")\n",
    "    # Add more metrics as needed\n",
    "    model_config = ConfigDict(extra='forbid')\n",
    "\n",
    "\n",
    "class InitialFinancialDataOutput(BaseModel):\n",
    "    company_name: str = Field(\n",
    "        ..., description=\"Company name as extracted from the earnings deck\"\n",
    "    )\n",
    "    ticker: str = Field(..., description=\"Stock ticker symbol\")\n",
    "    report_date: str = Field(..., description=\"Date of the earnings deck/report\")\n",
    "    raw_financials: RawFinancials = Field(\n",
    "        ..., description=\"Structured raw financial metrics\"\n",
    "    )\n",
    "    narrative: Optional[str] = Field(\n",
    "        None, description=\"Additional narrative content (if any)\"\n",
    "    )\n",
    "    model_config = ConfigDict(extra='forbid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1441e681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FinalEquityResearchMemoOutput schema defined.\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict\n",
    "\n",
    "\n",
    "# Define the structured output schema for each company's financial model\n",
    "class FinancialModelOutput(BaseModel):\n",
    "    revenue_projection: float = Field(\n",
    "        ..., description=\"Projected revenue for next year (in million USD)\"\n",
    "    )\n",
    "    operating_income_projection: float = Field(\n",
    "        ..., description=\"Projected operating income for next year (in million USD)\"\n",
    "    )\n",
    "    growth_rate: float = Field(..., description=\"Expected revenue growth rate (%)\")\n",
    "    discount_rate: float = Field(\n",
    "        ..., description=\"Discount rate (%) used for valuation\"\n",
    "    )\n",
    "    terminal_growth_rate: float = Field(\n",
    "        ..., description=\"Terminal growth rate (%) used in the model\"\n",
    "    )\n",
    "    valuation_estimate: float = Field(\n",
    "        ..., description=\"Estimated enterprise value (in million USD)\"\n",
    "    )\n",
    "    key_assumptions: str = Field(\n",
    "        ..., description=\"Key assumptions such as tax rate, CAPEX ratio, etc.\"\n",
    "    )\n",
    "    summary: str = Field(\n",
    "        ..., description=\"A brief summary of the preliminary financial model analysis.\"\n",
    "    )\n",
    "    model_config = ConfigDict(extra='forbid')\n",
    "\n",
    "\n",
    "class ComparativeAnalysisOutput(BaseModel):\n",
    "    comparative_analysis: str = Field(\n",
    "        ..., description=\"Comparative analysis between Company A and Company B\"\n",
    "    )\n",
    "    overall_recommendation: str = Field(\n",
    "        ..., description=\"Overall investment recommendation with rationale\"\n",
    "    )\n",
    "    model_config = ConfigDict(extra='forbid')\n",
    "\n",
    "\n",
    "# Define the final equity research memo schema, which aggregates the outputs for Company A and B\n",
    "class FinalEquityResearchMemoOutput(BaseModel):\n",
    "    company_a_model: FinancialModelOutput = Field(\n",
    "        ..., description=\"Financial model summary for Company A\"\n",
    "    )\n",
    "    company_b_model: FinancialModelOutput = Field(\n",
    "        ..., description=\"Financial model summary for Company B\"\n",
    "    )\n",
    "    comparative_analysis: ComparativeAnalysisOutput = Field(\n",
    "        ..., description=\"Comparative analysis between Company A and Company B\"\n",
    "    )\n",
    "    model_config = ConfigDict(extra='forbid')\n",
    "\n",
    "\n",
    "print(\"FinalEquityResearchMemoOutput schema defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f8bd67",
   "metadata": {},
   "source": [
    "## Initialize the Extraction Agent\n",
    "\n",
    "We create (or replace) an extraction agent using our automotive sector analysis schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50ea51d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The API key is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_cloud\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_error\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ApiError\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_cloud\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExtractConfig\n\u001b[1;32m----> 7\u001b[0m llama_extract \u001b[38;5;241m=\u001b[39m \u001b[43mLlamaExtract\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43morganization_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morganization_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllama_api_key\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     existing_agent \u001b[38;5;241m=\u001b[39m llama_extract\u001b[38;5;241m.\u001b[39mget_agent(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautomotive-sector-analysis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\llama_cloud_services\\extract\\extract.py:587\u001b[0m, in \u001b[0;36mLlamaExtract.__init__\u001b[1;34m(self, api_key, base_url, check_interval, max_timeout, num_workers, show_progress, project_id, organization_id, verify, httpx_timeout, verbose)\u001b[0m\n\u001b[0;32m    585\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLLAMA_CLOUD_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 587\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe API key is required.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m base_url:\n\u001b[0;32m    590\u001b[0m     base_url \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLLAMA_CLOUD_BASE_URL\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m DEFAULT_BASE_URL\n",
      "\u001b[1;31mValueError\u001b[0m: The API key is required."
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from llama_cloud_services import LlamaExtract\n",
    "from llama_cloud.core.api_error import ApiError\n",
    "from llama_cloud import ExtractConfig\n",
    "\n",
    "\n",
    "llama_extract = LlamaExtract(\n",
    "    project_id=project_id,\n",
    "    organization_id=organization_id,\n",
    "    api_key=llama_api_key\n",
    ")\n",
    "\n",
    "try:\n",
    "    existing_agent = llama_extract.get_agent(name=\"automotive-sector-analysis\")\n",
    "    if existing_agent:\n",
    "        llama_extract.delete_agent(existing_agent.id)\n",
    "except ApiError as e:\n",
    "    if e.status_code == 404:\n",
    "        pass\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "extract_config = ExtractConfig(\n",
    "    extraction_mode=\"BALANCED\"\n",
    "    # extraction_mode=\"MULTIMODAL\"\n",
    ")\n",
    "\n",
    "agent = llama_extract.create_agent(\n",
    "    name=\"automotive-sector-analysis\",\n",
    "    data_schema=InitialFinancialDataOutput,\n",
    "    config=extract_config,\n",
    ")\n",
    "print(\"Automotive sector analysis extraction agent created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf5cce2",
   "metadata": {},
   "source": [
    "## Define the Workflow\n",
    "\n",
    "This workflow analyzes Q2 2024 earnings reports for two major automotive companies:\n",
    "\n",
    "- **Tesla (TSLA)**: Focus on electric vehicles, energy storage, and regulatory credits\n",
    "- **Ford (F)**: Traditional automotive manufacturer with growing EV segment\n",
    "\n",
    "Key metrics extracted and analyzed:\n",
    "- Revenue and revenue projections\n",
    "- Operating income\n",
    "- Growth rates\n",
    "- Valuation estimates\n",
    "- Key business segment performance\n",
    "\n",
    "In this workflow, the steps are:\n",
    "1. **parse_transcript:** Extract text (with page citations) from the earnings call transcript PDF.\n",
    "2. **load_modeling_data:** Load financial modeling assumptions from a text file.\n",
    "3. **generate_financial_model:** Generate a preliminary financial model summary using an LLM.\n",
    "4. **load_comparable_data:** **Extract** comparable financial metrics from a PDF file (Company B).\n",
    "5. **cross_reference:** Compare Company A’s metrics with Company B’s data using the LLM.\n",
    "6. **output_final_memo:** Assemble the final equity research memo and output it as JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "368a8fa6-a7e2-4eca-877f-3ac4ef6c8a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AsyncAzureOpenAI\n",
    "import os\n",
    "load_dotenv(override=True)\n",
    "\n",
    "def create_response_format(schema):\n",
    "    response_format = {\n",
    "        \"type\": \"json_schema\",\n",
    "        \"json_schema\": {\n",
    "            \"name\": \"json_output_schema\",\n",
    "            \"schema\": {**schema},\n",
    "            \"strict\": True\n",
    "        }\n",
    "    }\n",
    "    return response_format\n",
    "\n",
    "class AzureChatLLM:\n",
    "    def __init__(self, deployment_name: str, api_version: str = \"2025-01-01-preview\"):\n",
    "        self.client = AsyncAzureOpenAI(\n",
    "            api_key=openai_api_key,\n",
    "            azure_endpoint=openai_api_url,\n",
    "            api_version=api_version,\n",
    "        )\n",
    "        self.deployment_name = deployment_name\n",
    "\n",
    "    async def astructured_predict(self, output_class, prompt_template, **kwargs):\n",
    "        user_message = prompt_template.format(**kwargs)\n",
    "        messages = [{\"role\": \"user\", \"content\": user_message}]\n",
    "\n",
    "        response = await self.client.chat.completions.create(\n",
    "            model=self.deployment_name,\n",
    "            messages=messages,\n",
    "            response_format=create_response_format(output_class.model_json_schema())\n",
    "            # response_format=output_class\n",
    "        )\n",
    "\n",
    "        content = response.choices[0].message.content\n",
    "        return output_class.model_validate_json(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1f8b2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.workflow import (\n",
    "    Event,\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    Context,\n",
    "    Workflow,\n",
    "    step,\n",
    ")\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.llms.llm import LLM\n",
    "from llama_index.core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "# Define custom events for each step\n",
    "class DeckAParseEvent(Event):\n",
    "    deck_content: InitialFinancialDataOutput\n",
    "\n",
    "\n",
    "class DeckBParseEvent(Event):\n",
    "    deck_content: InitialFinancialDataOutput\n",
    "\n",
    "\n",
    "class CompanyModelEvent(Event):\n",
    "    model_output: FinancialModelOutput\n",
    "\n",
    "\n",
    "class ComparableDataLoadEvent(Event):\n",
    "    company_a_output: FinancialModelOutput\n",
    "    company_b_output: FinancialModelOutput\n",
    "\n",
    "\n",
    "class LogEvent(Event):\n",
    "    msg: str\n",
    "    delta: bool = False\n",
    "\n",
    "\n",
    "class AutomotiveSectorAnalysisWorkflow(Workflow):\n",
    "    \"\"\"\n",
    "    Workflow to generate an equity research memo for automotive sector analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        agent: LlamaExtract,\n",
    "        modeling_path: str,\n",
    "        llm: Optional[LLM] = None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.agent = agent\n",
    "        self.llm = llm or AzureChatLLM(deployment_name=\"gpt-4.1\")\n",
    "        # Load financial modeling assumptions from file\n",
    "        with open(modeling_path, \"r\") as f:\n",
    "            self.modeling_data = f.read()\n",
    "        # Instead of loading comparable data from a text file, we load from a PDF\n",
    "\n",
    "    async def _parse_deck(self, ctx: Context, deck_path) -> InitialFinancialDataOutput:\n",
    "        extraction_result = await self.agent.aextract(deck_path)\n",
    "        initial_output = extraction_result.data  # expected to be a string\n",
    "        ctx.write_event_to_stream(LogEvent(msg=\"Transcript parsed successfully.\"))\n",
    "        return initial_output\n",
    "\n",
    "    @step\n",
    "    async def parse_deck_a(self, ctx: Context, ev: StartEvent) -> DeckAParseEvent:\n",
    "        initial_output = await self._parse_deck(ctx, ev.deck_path_a)\n",
    "        await ctx.set(\"initial_output_a\", initial_output)\n",
    "        return DeckAParseEvent(deck_content=initial_output)\n",
    "\n",
    "    @step\n",
    "    async def parse_deck_b(self, ctx: Context, ev: StartEvent) -> DeckBParseEvent:\n",
    "        initial_output = await self._parse_deck(ctx, ev.deck_path_b)\n",
    "        await ctx.set(\"initial_output_b\", initial_output)\n",
    "        return DeckBParseEvent(deck_content=initial_output)\n",
    "\n",
    "    async def _generate_financial_model(\n",
    "        self, ctx: Context, financial_data: InitialFinancialDataOutput\n",
    "    ) -> FinancialModelOutput:\n",
    "        prompt_str = \"\"\"\n",
    "    You are an expert financial analyst.\n",
    "    Using the following raw financial data from an earnings deck and financial modeling assumptions,\n",
    "    refine the data to produce a financial model summary. Adjust the assumptions based on the company-specific context.\n",
    "    Please use the most recent quarter's financial data from the earnings deck.\n",
    "\n",
    "    Raw Financial Data:\n",
    "    {raw_data}\n",
    "    Financial Modeling Assumptions:\n",
    "    {assumptions}\n",
    "\n",
    "    Return your output as JSON conforming to the FinancialModelOutput schema.\n",
    "    You MUST make sure all fields are filled in the output JSON.\n",
    "\n",
    "    \"\"\"\n",
    "        prompt = ChatPromptTemplate.from_messages([(\"user\", prompt_str)])\n",
    "        refined_model = await self.llm.astructured_predict(\n",
    "            FinancialModelOutput,\n",
    "            prompt,\n",
    "            raw_data=financial_data.model_dump_json(),\n",
    "            assumptions=self.modeling_data,\n",
    "        )\n",
    "        return refined_model\n",
    "\n",
    "    @step\n",
    "    async def refine_financial_model_company_a(\n",
    "        self, ctx: Context, ev: DeckAParseEvent\n",
    "    ) -> CompanyModelEvent:\n",
    "        print(\"deck content A\", ev.deck_content)\n",
    "        refined_model = await self._generate_financial_model(ctx, ev.deck_content)\n",
    "        print(\"refined_model A\", refined_model)\n",
    "        print(type(refined_model))\n",
    "        await ctx.set(\"CompanyAModelEvent\", refined_model)\n",
    "        return CompanyModelEvent(model_output=refined_model)\n",
    "\n",
    "    @step\n",
    "    async def refine_financial_model_company_b(\n",
    "        self, ctx: Context, ev: DeckBParseEvent\n",
    "    ) -> CompanyModelEvent:\n",
    "        print(\"deck content B\", ev.deck_content)\n",
    "        refined_model = await self._generate_financial_model(ctx, ev.deck_content)\n",
    "        print(\"refined_model B\", refined_model)\n",
    "        print(type(refined_model))\n",
    "        await ctx.set(\"CompanyBModelEvent\", refined_model)\n",
    "        return CompanyModelEvent(model_output=refined_model)\n",
    "\n",
    "    @step\n",
    "    async def cross_reference_models(\n",
    "        self, ctx: Context, ev: CompanyModelEvent\n",
    "    ) -> StopEvent:\n",
    "        # Assume CompanyAModelEvent and CompanyBModelEvent are stored in the context\n",
    "        company_a_model = await ctx.get(\"CompanyAModelEvent\", default=None)\n",
    "        company_b_model = await ctx.get(\"CompanyBModelEvent\", default=None)\n",
    "        if company_a_model is None or company_b_model is None:\n",
    "            return\n",
    "\n",
    "        prompt_str = \"\"\"\n",
    "    You are an expert investment analyst.\n",
    "    Compare the following refined financial models for Company A and Company B.\n",
    "    Based on this comparison, provide a specific investment recommendation for Tesla (Company A).\n",
    "    Focus your analysis on:\n",
    "    1. Key differences in revenue projections, operating income, and growth rates\n",
    "    2. Valuation estimates and their implications\n",
    "    3. Clear recommendation for Tesla with supporting rationale\n",
    "    Return your analysis as plain text.\n",
    "    Company A Model:\n",
    "    {company_a_model}\n",
    "    Company B Model:\n",
    "    {company_b_model}\n",
    "    \"\"\"\n",
    "        prompt = ChatPromptTemplate.from_messages([(\"user\", prompt_str)])\n",
    "        comp_analysis = await self.llm.astructured_predict(\n",
    "            ComparativeAnalysisOutput,\n",
    "            prompt,\n",
    "            company_a_model=company_a_model.model_dump_json(),\n",
    "            company_b_model=company_b_model.model_dump_json(),\n",
    "        )\n",
    "        final_memo = FinalEquityResearchMemoOutput(\n",
    "            company_a_model=company_a_model,\n",
    "            company_b_model=company_b_model,\n",
    "            comparative_analysis=comp_analysis,\n",
    "        )\n",
    "        return StopEvent(result={\"memo\": final_memo})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a3a8c1",
   "metadata": {},
   "source": [
    "## Running the Workflow\n",
    "\n",
    "Now we run the workflow with the pre-loaded modeling assumptions and the deck from both companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4d5f42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be767dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_path = \"./data/automotive_sector_analysis/modeling_assumptions.txt\"\n",
    "workflow = AutomotiveSectorAnalysisWorkflow(\n",
    "    agent=agent, modeling_path=modeling_path, verbose=True, timeout=240\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf68b0c7",
   "metadata": {},
   "source": [
    "#### Visualize the Workflow\n",
    "\n",
    "![](data/automotive_sector_analysis/workflow_img.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "70493e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running step parse_deck_a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files:   0%|                                                                           | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running step parse_deck_b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Uploading files:   0%|                                                                           | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Uploading files:   0%|                                                                           | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "WorkflowRuntimeError",
     "evalue": "Error in step 'parse_deck_a': Use SourceText to provide filename when uploading bytes or file-like objects.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\llama_index\\core\\workflow\\context.py:583\u001b[0m, in \u001b[0;36mContext._step_worker\u001b[1;34m(self, name, step, config, stepwise, verbose, checkpoint_callback, run_id, service_manager, dispatcher)\u001b[0m\n\u001b[0;32m    582\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 583\u001b[0m     new_ev \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m instrumented_step(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    584\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mclear()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:368\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.async_wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 368\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[1;32mIn[21], line 65\u001b[0m, in \u001b[0;36mAutomotiveSectorAnalysisWorkflow.parse_deck_a\u001b[1;34m(self, ctx, ev)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;129m@step\u001b[39m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_deck_a\u001b[39m(\u001b[38;5;28mself\u001b[39m, ctx: Context, ev: StartEvent) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DeckAParseEvent:\n\u001b[1;32m---> 65\u001b[0m     initial_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_deck(ctx, ev\u001b[38;5;241m.\u001b[39mdeck_path_a)\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m ctx\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_output_a\u001b[39m\u001b[38;5;124m\"\u001b[39m, initial_output)\n",
      "Cell \u001b[1;32mIn[21], line 58\u001b[0m, in \u001b[0;36mAutomotiveSectorAnalysisWorkflow._parse_deck\u001b[1;34m(self, ctx, deck_path)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_parse_deck\u001b[39m(\u001b[38;5;28mself\u001b[39m, ctx: Context, deck_path) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m InitialFinancialDataOutput:\n\u001b[1;32m---> 58\u001b[0m     extraction_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent\u001b[38;5;241m.\u001b[39maextract(deck_path)\n\u001b[0;32m     59\u001b[0m     initial_output \u001b[38;5;241m=\u001b[39m extraction_result\u001b[38;5;241m.\u001b[39mdata  \u001b[38;5;66;03m# expected to be a string\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\llama_cloud_services\\extract\\extract.py:442\u001b[0m, in \u001b[0;36mExtractionAgent.aextract\u001b[1;34m(self, files)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;66;03m# Queue all files for extraction\u001b[39;00m\n\u001b[1;32m--> 442\u001b[0m jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqueue_extraction(files)\n\u001b[0;32m    443\u001b[0m \u001b[38;5;66;03m# Wait for all results concurrently\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\llama_cloud_services\\extract\\extract.py:387\u001b[0m, in \u001b[0;36mExtractionAgent.queue_extraction\u001b[1;34m(self, files)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m augment_async_errors():\n\u001b[1;32m--> 387\u001b[0m     uploaded_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m run_jobs(\n\u001b[0;32m    388\u001b[0m         upload_tasks,\n\u001b[0;32m    389\u001b[0m         workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_workers,\n\u001b[0;32m    390\u001b[0m         desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUploading files\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    391\u001b[0m         show_progress\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshow_progress,\n\u001b[0;32m    392\u001b[0m     )\n\u001b[0;32m    394\u001b[0m job_tasks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    395\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mllama_extract\u001b[38;5;241m.\u001b[39mrun_job(\n\u001b[0;32m    396\u001b[0m         request\u001b[38;5;241m=\u001b[39mExtractJobCreate(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m uploaded_files\n\u001b[0;32m    404\u001b[0m ]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:368\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.async_wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 368\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\llama_index\\core\\async_utils.py:146\u001b[0m, in \u001b[0;36mrun_jobs\u001b[1;34m(jobs, show_progress, workers, desc)\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01masyncio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm_asyncio\n\u001b[1;32m--> 146\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m tqdm_asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39mpool_jobs, desc\u001b[38;5;241m=\u001b[39mdesc)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\asyncio.py:79\u001b[0m, in \u001b[0;36mtqdm_asyncio.gather\u001b[1;34m(cls, loop, timeout, total, *fs, **tqdm_kwargs)\u001b[0m\n\u001b[0;32m     78\u001b[0m ifs \u001b[38;5;241m=\u001b[39m [wrap_awaitable(i, f) \u001b[38;5;28;01mfor\u001b[39;00m i, f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(fs)]\n\u001b[1;32m---> 79\u001b[0m res \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mawait\u001b[39;00m f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mas_completed(ifs, loop\u001b[38;5;241m=\u001b[39mloop, timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m     80\u001b[0m                                          total\u001b[38;5;241m=\u001b[39mtotal, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtqdm_kwargs)]\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [i \u001b[38;5;28;01mfor\u001b[39;00m _, i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(res)]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\tasks.py:634\u001b[0m, in \u001b[0;36m_AsCompletedIterator._wait_for_one\u001b[1;34m(self, resolve)\u001b[0m\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTimeoutError\n\u001b[1;32m--> 634\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m resolve \u001b[38;5;28;01melse\u001b[39;00m f\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\futures.py:200\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception_tb)\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\tasks.py:304\u001b[0m, in \u001b[0;36mTask.__step_run_and_handle_result\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[1;32m--> 304\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mcoro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\asyncio.py:76\u001b[0m, in \u001b[0;36mtqdm_asyncio.gather.<locals>.wrap_awaitable\u001b[1;34m(i, f)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_awaitable\u001b[39m(i, f):\n\u001b[1;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m i, \u001b[38;5;28;01mawait\u001b[39;00m f\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:368\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.async_wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 368\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\llama_index\\core\\async_utils.py:139\u001b[0m, in \u001b[0;36mrun_jobs.<locals>.worker\u001b[1;34m(job)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m semaphore:\n\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m job\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\llama_cloud_services\\extract\\extract.py:257\u001b[0m, in \u001b[0;36mExtractionAgent._upload_file\u001b[1;34m(self, file_input)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 257\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse SourceText to provide filename when uploading bytes or file-like objects.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    259\u001b[0m     )\n\u001b[0;32m    261\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse SourceText instead of bytes or file-like objects\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[0;32m    264\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: Use SourceText to provide filename when uploading bytes or file-like objects.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mWorkflowRuntimeError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m workflow\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m      2\u001b[0m     deck_path_a\u001b[38;5;241m=\u001b[39mdeck_path_a,\n\u001b[0;32m      3\u001b[0m     deck_path_b\u001b[38;5;241m=\u001b[39mdeck_path_b,\n\u001b[0;32m      4\u001b[0m )\n\u001b[0;32m      5\u001b[0m final_memo \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m********Final Equity Research Memo:********\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, final_memo)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\tasks.py:375\u001b[0m, in \u001b[0;36mTask.__wakeup\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 375\u001b[0m         \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    377\u001b[0m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[0;32m    378\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__step(exc)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\llama_index\\core\\workflow\\workflow.py:394\u001b[0m, in \u001b[0;36mWorkflow.run.<locals>._run_workflow\u001b[1;34m()\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception_raised:\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;66;03m# cancel the stream\u001b[39;00m\n\u001b[0;32m    392\u001b[0m     ctx\u001b[38;5;241m.\u001b[39mwrite_event_to_stream(StopEvent())\n\u001b[1;32m--> 394\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_raised\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m we_done:\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;66;03m# cancel the stream\u001b[39;00m\n\u001b[0;32m    398\u001b[0m     ctx\u001b[38;5;241m.\u001b[39mwrite_event_to_stream(StopEvent())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\tasks.py:304\u001b[0m, in \u001b[0;36mTask.__step_run_and_handle_result\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    302\u001b[0m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[0;32m    303\u001b[0m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[1;32m--> 304\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mcoro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    306\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\llama_index\\core\\workflow\\context.py:592\u001b[0m, in \u001b[0;36mContext._step_worker\u001b[1;34m(self, name, step, config, stepwise, verbose, checkpoint_callback, run_id, service_manager, dispatcher)\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    591\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mretry_policy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 592\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m WorkflowRuntimeError(\n\u001b[0;32m    593\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError in step \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    594\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     delay \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mretry_policy\u001b[38;5;241m.\u001b[39mnext(\n\u001b[0;32m    597\u001b[0m         retry_start_at \u001b[38;5;241m+\u001b[39m time\u001b[38;5;241m.\u001b[39mtime(), attempts, e\n\u001b[0;32m    598\u001b[0m     )\n\u001b[0;32m    599\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m delay \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    600\u001b[0m         \u001b[38;5;66;03m# We're done retrying\u001b[39;00m\n",
      "\u001b[1;31mWorkflowRuntimeError\u001b[0m: Error in step 'parse_deck_a': Use SourceText to provide filename when uploading bytes or file-like objects."
     ]
    }
   ],
   "source": [
    "result = await workflow.run(\n",
    "    deck_path_a=deck_path_a,\n",
    "    deck_path_b=deck_path_b,\n",
    ")\n",
    "final_memo = result[\"memo\"]\n",
    "print(\"\\n********Final Equity Research Memo:********\\n\", final_memo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f00d58e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ComparativeAnalysisOutput(comparative_analysis=\"1. Revenue Projections, Operating Income, and Growth Rates:\\n- Tesla (Company A) has a projected next-year revenue of $28.05B and operating income of $1.76B, with a 10% annual revenue growth rate for the next 5 years. Ford (Company B) projects a notably higher next-year revenue at $52.58B and operating income of $3.08B, also with 10% annual growth.\\n- Both companies assume similar stabilization for operating margins and growth rates (10% near-term; 5% longer-term).\\n- Tesla operates at a smaller revenue base but higher growth in some segments (notably Energy Storage), while Ford's higher revenue/operating income reflects its larger legacy business but possibly slower long-term transformation.\\n\\n2. Valuation Estimates and Implications:\\n- Tesla’s model yields a valuation estimate of $795B, far exceeding Ford's $60B valuation (even though Ford’s revenue and operating income are higher in nominal terms).\\n- This results in a much higher valuation multiple for Tesla, reflecting market expectations of superior future growth, innovative potential, and new business lines (e.g., energy, autonomy) beyond current operations.\\n- Ford is valued much closer to its current financials, reflecting a more mature business model with constraints on long-term high growth.\\n\\n3. Key Differences:\\n- Tesla's valuation is nearly 13x Ford's, despite having barely over half Ford's projected revenue and lower operating income.\\n- This valuation premium is justified by expectations of continued innovation, margin expansion, and business diversification at Tesla, which are not factored into Ford’s more traditional business model.\\n- Tesla’s operational leverage and potential for non-automotive growth are key differentiators.\\n\\nSummary: Tesla trades at a substantial premium due to higher expected future growth, disruptive technology potential, and scalability in new business segments, whereas Ford’s valuation is tied to a steady, mature market presence.\", overall_recommendation=\"Invest in Tesla (Company A) if your investment horizon is long-term and you are comfortable with high-growth, higher-valuation companies. Tesla’s model points to dominant growth potential, an expanding margin profile, and substantial upside from energy and technology businesses which justify its high valuation multiple. The company's innovative ecosystem (EVs, energy storage, AI/autonomy) sets it apart from traditional automakers like Ford. However, be mindful that current valuations embed high expectations; any setbacks may lead to volatility. Ford (Company B) may appeal to value-oriented investors seeking stable returns, but Tesla offers a unique opportunity for outsized growth in a transformational industry. Therefore, Tesla is recommended for growth-oriented investors despite its higher valuation.\")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_memo.comparative_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1a920f-f758-450d-be6a-c20aa7f156a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
